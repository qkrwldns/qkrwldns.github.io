---
title: 딥러닝 공부 2024.05.27
author: cotes
date: 2024.05.27 17:33:00 +0800
categories: [폴리텍, 딥러닝]
tags: [딥러닝]
pin: true
math: true
mermaid: true
image:
  path: https://images-ctf.baslerweb.com/dg51pdwahxgw/6DUrPe1CgaJhAION8iNUSP/ddb583f2a86808b6718e43fd78f43103/VC_Deep_Learning_Hero_3200x1800.webp?fm=webp&f=center&w=1400&q=80&fit=pad
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt: 딥러닝 img
---

## yolo 모델 테스트

![이미지1](./assets/poly/deepLearning/2024-05-27/yolo(1).png)  
컴퓨터 실행 환경  
![이미지1](./assets/poly/deepLearning/2024-05-27/yolo(1).png)  
네트워크 망이 어케 구성되어있나

## gui 기반 사람 인식

```py
import tkinter as tk
from tkinter import filedialog
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.figure import Figure
import cv2
from ultralytics import YOLO

# Initialize YOLO model
model = YOLO('yolov8n.pt')

# 전역 변수로 캔버스를 관리
canvas = None

def load_image():
    global canvas
    file_path = filedialog.askopenfilename()
    if file_path:
        results = model.predict(file_path)
        for i, result in enumerate(results):
            img = result.plot()
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            display_image(img_rgb)

def display_image(img_rgb):
    global canvas
    fig = Figure(figsize=(6, 4), dpi=100)
    fig.add_subplot(111).imshow(img_rgb)
    fig.axes[0].axis('off')  # Hide axes

    if canvas:  # 이전 캔버스가 존재한다면 제거
        canvas.get_tk_widget().destroy()

    canvas = FigureCanvasTkAgg(fig, master=window)
    canvas.draw()
    canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)

# Main window
window = tk.Tk()
window.title('YOLO Object Detection')
window.geometry('800x600')  # 창 크기를 800x600 픽셀로 설정

# Menu button for loading images
load_button = tk.Button(window, text='Load Image', command=load_image)
load_button.pack(side=tk.BOTTOM)

window.mainloop()
```

## gui 기반 포즈 인식

```py
import tkinter as tk
from tkinter import filedialog
import cv2
import mediapipe as mp
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.figure import Figure
from ultralytics import YOLO

# Initialize the model
model = YOLO('yolov8n.pt')  # Ensure the model file path is correct

mp_pose = mp.solutions.pose
pose = mp_pose.Pose()

def load_image():
    file_path = filedialog.askopenfilename()
    if file_path:
        image = cv2.imread(file_path)
        if image is None:
            print("Failed to load image.")
            return  # Exit the function if image is not loaded

        # Convert image for pose detection
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results_pose = pose.process(image_rgb)
        annotated_image = image_rgb.copy()
        mp.solutions.drawing_utils.draw_landmarks(
            annotated_image, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # Display image with pose annotations
        display_image(annotated_image)

def display_image(img_rgb):
    fig = Figure(figsize=(6, 4), dpi=100)
    fig.add_subplot(111).imshow(img_rgb)
    fig.axes[0].axis('off')

    global canvas
    if canvas:
        canvas.get_tk_widget().destroy()

    canvas = FigureCanvasTkAgg(fig, master=window)
    canvas.draw()
    canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)

# Main window
window = tk.Tk()
window.title('Pose Detection')
window.geometry('800x600')

# 전역 캔버스 변수 초기화
canvas = None

# Menu button for loading images
load_button = tk.Button(window, text='Load Image', command=load_image)
load_button.pack(side=tk.BOTTOM)

window.mainloop()

```

## gui 기반 동영상 포즈 인식

```py
import tkinter as tk
from tkinter import filedialog
import cv2
import mediapipe as mp
from PIL import Image, ImageTk

# Mediapipe 포즈 모델 초기화
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()

# 비디오 처리 및 GUI 업데이트
def process_video(video_path):
    cap = cv2.VideoCapture(video_path)
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # 포즈 처리
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(frame_rgb)

        # 포즈 랜드마크 그리기
        mp.solutions.drawing_utils.draw_landmarks(
            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # Tkinter 호환 이미지로 변환
        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        image_tk = ImageTk.PhotoImage(image=image)

        # GUI에 이미지 표시
        label.config(image=image_tk)
        label.image = image_tk
        label.update()

    cap.release()

# 파일 선택 및 비디오 처리 시작
def select_video():
    file_path = filedialog.askopenfilename()
    if file_path:
        process_video(file_path)

# GUI 설정
window = tk.Tk()
window.title('Real-time Pose Detection')

# 비디오 선택 버튼
select_button = tk.Button(window, text='Select Video', command=select_video)
select_button.pack()

# 이미지 표시 레이블
label = tk.Label(window)
label.pack()

window.mainloop()
```